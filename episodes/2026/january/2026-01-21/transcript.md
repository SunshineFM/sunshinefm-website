Sam, It's. You're listening to Sunshine fm, Modern Media, Palm Springs Coachella. That was one of our AI artists, Rani from London, out here on a PS Getaway. That's the name of her new album. And that was Racing Ghosts, a conversation about driving up 74 and looking out at the valley below. Anyway, that's Ronnie. Keep an eye on her. She's gonna go far. Sunshine fm Modern Media for Palm Springs Coachella. Here's a quick little break in the music and I want to talk about Dario Amodei. For those that may not know, Dario Amodei is the CEO founder of Anthropic, one of the three large foundational AI models that we're all basically experiencing working with, impacting the world as we know it. The one you may already know is OpenAI with ChatGPT. The other one that you may be exposed to on a constant basis is Google's Gemini because of their surface area. The one you may not know is Anthropic, the makers of Claude Claude AI. And if you're a developer, you are already playing with Claude because it's one of your preferred foundational models. They happen to be the foundational model where a whole bunch of other coding tools are being built on, such as cursor and replit. And why I'm bringing up Dario this today is for some comments that he made over the last 48 hours. And so let me today's kind of show is going to be a little bit different. And what I mean by that is I'm just going to be talking about this kind of impact that his comments made, not just on me, but on the AI industry and basically society itself. If you were listening or you're tuned into what Daria Amade may be saying, which, you know, if you're in the AI world, you are on a daily basis. Dario Amadei, the CEO of Anthropic, he basically gave interviews at Davos. He spoke to a couple of major media outlets as well. And he made some specific points about what governments actually need to do right now. Not in five years and not when the problem gets worse. His his words, but now. And what's interesting isn't just what he's warning about, it's what he's proposing as the fix. And whether that fix actually works depends on whether governments listen. So let me go ahead and put this down in segments and we'll talk about each segment. Okay? What he said at Davos in the last 48 hours, he framed it pretty carefully because he is a pretty good storyteller and an owner of the narrative. But his math is pretty clear. And this is kind of like the I say the clippable snippets talking points that least got me so interested to do a bit more deep dive into this. Right. Two basic numbers. He thinks we could see 5 to 10% GDP growth at the same time as 10 to 20% unemployment. He's not hedging. He said the next few years are critical for how we regulate and govern this technology because regulation and governance choices now shape what actually happens. So that was his framing. High productivity, which if you're listening to the show and if you come to our workshops, you know that's what we think the promise of AI is high productivity, uneven distribution and real economic pain for real people. At the same time, the overall economy looks strong on paper. Now I think for a lot of us are feeling that anyway, with or without AI. But just in the lens and the framing of why Sunshine FM exists, it's all about AI and how AI and this technology is going to shape work, life, culture and pretty much every, every touch point that we have, it only already feels uneven in terms of the distribution. And here's something else that he said, kind of a bit more specific. He thinks AI could eliminate half of all entry level white collar jobs. Not eventually. He's already seeing it happen in the coding industry. Again, we can go back and forth on this. I have conversations like this on a daily basis. All last year in 2025 in our workshops we had this back and forth and nobody knows exactly where this is headed. And I had folks pushing back on me when I would, let's say, take on the non optimistic approach that it could eliminate entry level jobs. I mean, that's the whole reason AICV was created in the first place, is to be that bridge between the new workforce, which are kids in high school and college, and and them getting on the career ladder. That chasm is widening and AIC was created to be that bridge through training of AI fluency and trying to be a talent marketplace for small businesses that need this talent and for talent to get connected to small businesses and enterprises locally. This is still an open conversation and this space is a safe space for you to come on and have this conversation back and forth. Because at the end of the day it's these conversations that we all will learn from. And I also am open to learning. I'm a lifelong student, so I want to learn from other people with various viewpoints. Reason why I'm bringing this up today is Because Dari Amade is not just a me in the Coachella Valley. He, he happens to run one of the top three AI companies in the world. And so while it may not be gospel, his words have a certain sense of depth and credibility. So he carries on. So, you know, reading all his, all the transcriptions from what he said over the last, you know, 72 hours, I was trying to synthesize and pull out what it might mean for us locally and locally. Look, entry level jobs have always been a way how people learn trades. It's how someone without connections gets their first shot. And they're the rungs of the ladder, right? And if those rungs begin disappearing faster than the economy creates new ones, we don't just have a job workforce problem, we actually have a society social problem. Now, Daria Amadei knows this. He's not just theorizing. He said he's watching usage patterns by income level. And here's what he's seeing. In wealthy areas, people use AI to enhance what they already do. It's a productivity tool for people who already have skills and jobs. In lower income areas, people are using AI to learn, trying to scale up without formal education, trying to teach themselves their way into a job. We saw this firsthand in our 30 or so workshops that we did last year. But if the entry level jobs are disappearing, then we have a problem. People are using AI to try to learn their way into positions that might not exist. That gap between hope you can skill up and there might be a, there might not be a job waiting. That's where things get real again. That chasm I was talking about, I've had conversations with university professors and deans and academics, and it disappoints. So let's just say surprises me still that two and a half years later since I started having these conversations, we are still at the same place. And that the formalized infrastructure of teaching AI and training AI and letting the next workforce be AI fluent is still not integrated in our educational systems. Now, I did a whole deep dive on that AI in education last week, so feel free to go back to one of those. While the episodes aren't real or live or recorded anywhere, there are transcripts of them at Sunshine fm, so you can always just read some of those. Now we are planning on going into some, let's say best of radio show into a podcast, but that's down the line. So that's the setup from Daria Amade. So let's continue based on what else he said and what are the Segments and sectors of what he said I found pretty interesting and I'm going to try and synthesize of what it might mean for Palm Springs Coachella. So part two was possible proposal for a government solution. Now, Amadei didn't call for AI to be banned or heavily restricted in a way that kills innovation. He actually called for something more specific and possibly in some ways just harder to implement. He called for what he calls a federal transparency standard. And while last year he described in a New York Times op ed, since then he's repeated it and he's kind of staying true to his kind of thought process. Requirement number one, AI companies that are building frontier models, the most powerful ones, should be required to publicly disclose their testing policies. What tests are they running? How are they evaluating the capabilities and risks. Requirement two, companies have to outline on their websites publicly, where anyone can see it, what steps they're taking to test for and mitigate national security risks and other catastrophic risks. And requirement three, after they do the testing, they have to be upfront about what they found and what changes they made to make sure they the model is safe before releasing it. Basically he's saying it's not that you can build I and not the government controls everything. It's more like be honest about what you tested, about what you found and what you did about it. And so why is he proposing this instead of something stricter? He was basically reacting to a Republican proposal for a 10 year moratorium on all state AI regulations. And he basically said that's far too blunt an instrument. His argument was AI is advancing so fast that a 10 year ban would give you the worst of both worlds. No state could act and no national policy would replace it. You'd be frozen. Instead, what he was saying was the White House and Congress should work together on federal standards that are narrowly focused on transparency and not overly prescriptive or burdensome. And if those federal standards exist, states could then defer to them or write the wrong rules that fit the same model. He's basically aiming for a middle path. Not that tech companies should police themselves because we know how that's worked in social media, and not that governments micromanage innovation. It's purely government set transparency requirements, companies comply and the public gets visibility into what's being tested and what risks are being found. Now, I, I mean he's basically talking his own book, right? At the end of the day, those are a little bit, not, I wouldn't say potshots, but he's taking shots at a whole bunch of Startups and let's say OpenAI that are basically just trying to throw spaghetti on the wall, or as I heard one of the journalists say yesterday, throwing pancakes on the wall and seeing what sticks. He and Claude have made a bet that safety and transparency is the way to go forward. And he's obviously benefiting from that because Anthropic is a very trusted and safe brand, at least for those of US building in AI Part 3. Why he thinks the government has to move now, the urgency. Right. He basically suggests that producers of this technology have a duty and obligation to be honest about what is coming. And he said it's a very strange set of dynamics. You should be worried about where the technology we're building is going to. And while the critics reply, we don't believe you, you're just hyping it up. And what if they're right? Translation. He's worried that tech companies warning about AI risks won't be believed until something bad happens. And by then it's too late to set up guardrails. And so in a 60 Minutes appearance in November, I'm going back a bit just for context based on I'm going to lead back up to what he said in the last couple of days. His company ran a test on Claude, which was the latest AI model back late last year, and they gave it access to a hypothetical scenario with emails. It was told to make it look bad. And when Amadi told the system it would be shut down, Claude, the AI chatbot, threatened to share those embarrassing emails with his wife to prevent being shut down. The point being, the scenario isn't fiction. Anthropic's latest AI model demonstrated just a few weeks ago it was capable of this kind of behavior. These aren't theoretical problems. They're not what might happen in AGI. They're happening now in testing. The question is, what do we do about it before it scales? He goes on to talk about, and he mentioned this two days ago too, about the geopolitical layer and why chips matter. He basically strongly criticized administration's decision to allow sales of advanced Nvidia H200AI chips to China. Said it's a big mistake with incredible national security implications, similar to selling nuclear weapons to North Korea and then bragging that, oh, well, you know, Boeing did make the casings, so there's a lot to read into that. But again, he, he's not pulling any punches. He is speaking his own book that we, we get that. And keep in mind there's a lot of strange bedfellows in this not just political, but both within the tech companies, because one of the biggest investors in Anthropic is Nvidia. And Darius calling to not have more sales for Nvidia, which is kind of strange in and of itself. I think we should go. I could go deeper into geopolitical, but perhaps that's not for this show. Right. Maybe one of our workshops will do that. Right. The real tension, this is part five of what I kind of synthesized from his talking points lately, Is that AI capability is accelerating very, very fast. Models are getting more capable every few months, and the capabilities are arriving now. Coding, analysis, research, customer service, automation, all of it is happening right now. I talk about this on a daily basis. I experiment with this on a daily basis, and I share the results with you, both the good, the bad and the embarrassing. While AI capability is accelerating, the preparation for this new world, the social preparation, the legal, the educational, it is so, so slow. You've heard this in my own voice. That's the kind of exasperation I've felt over the last 18 to 24 months, is we can see what's happening technologically yet on the ground, social, legal, educational, the prep is so frustratingly slow. So Amadi is basically saying what I've been saying with a much, much smaller microphone. He is a big megaphone. We're saying the same thing. We have got to catch up. We have got to get this aligned. He says that he believes these systems could change the world fundamentally within two years. And in 10 years, well, all bets are off. The timeline is short. Going back to what he's saying, and the governments need to do, set standards, train people for new kinds of work, help communities adapt, set up oversight. And those do take time to implement. Well, but he says it needs to be done today. And if you're going to wait until disruption is obvious, you're already behind. I, you know, unfortunately, I do feel that our Coachella Valley region has historically been behind for a variety of, you know, let's say incentive reasons. I don't think this is going to be any different, but that doesn't mean we shouldn't continue pushing as much as we can. Right. That's the whole reason why Sunshine FM exists. So let's get into some of the local angles. This is section sec.6 that I kind of co wrote with one of my agents. Well, first of all, transparency standards are local. In effect, if the federal government says AI companies have to publicly disclose what they tested and what risks they found, that creates accountability. And it also creates a public record Researchers, educators, and policy makers. Let's just assume all local people, right, are folks who are in the institutions to get this information. They can actually look at what's being tested and think about what that means for their region. I do not. Actually, I shouldn't say that I should frame it this way. I have yet to see any report locally from a researcher or an educator or a policymaker that is looking into AI testing and what it might mean for our region. I think aicv, which is our training entity, we might be one of the only ones who are actually doing some deep research and then presenting it to our attendees at our workshops. If there are people in the 9 cities of Coachella Valley who are actually doing this, let me know, because this needs to be public and it needs to be out there for all 350,000 residents of the Coachella Valley. The second thing Amadei says is the urgency is so much so that we don't have years to figure this out. So conversations that I've also had, you know, if you're running a hospitality business in the Coachella Valley, you're probably not thinking about AI displacement of workers. You're thinking about occupancy rates in convention center renovations. Absolutely. That is exactly the conversations I've been having. Even the leaders of some of the biggest organizations who deal with hospitality, they do not think there's going to be displacement of hospitality workers because of AI. But going back to Amadi's point, the transition is already happening, and we can either adapt to it early or adapt to it after a crisis. The early adaptation, which is now actually was yesterday, but let's say the second best time is today, early adaptation is easier. And so third, if the federal standards he's proposing could create a floor for safety and transparency and implementation, depends on whether states, cities, schools and businesses engage with that floor or ignore it. And if a federal standard says AI developers must disclose risk mitigation steps, that's useful information. But it's only useful if local decision makers, the folks that I mentioned earlier, educators, business leaders, workforce developers, actually read those disclosures and think about what they mean. And that's where Palm Springs Coachella could enter the picture. Because this blueprint only works if governments and communities actually do something beyond just talking about it. I did write a bunch about what this means for government decision making, but I feel after my last couple of years of working with local policymakers, council members, I feel much of what I'm going to would talk about right now would fall on deaf ears. But if I'm wrong. Please, you know, reach out, you know, to get a hold of me. I'm at the event tonight at the Agua Caliente Cultural Museum. Happy to discuss this. And then let's get on the show. Let's, you know, come on this show and let's have a quick little, you know, conversation about what local governments really are doing about AI for its residents, for its businesses, and for the region in general. So, Dario amadai, he spent 48 hours at one of the world's most important conferences telling the people who make decisions on a global level, act now. Be transparent. Keep time open for adaptation. Remember his numbers, right? He believes a 5 to 10% GDP in America, which is. That's like that astounding. Number one, we'd currently run at 2% GDP. Imagine a 5 to 10%. It's. It's tough to imagine, especially right now, in the current economic conditions that most Americans find themselves in. So he's telling the leaders on a global scale this is what they need to do. I'm trying to synthesize it to a local scale and not trying to, you know, reinvent the wheel. Basically just parroting what AI companies have been saying for the last two and a half, three years and how it's going to impact us as local residents, citizens, business owners, students, and, let's say, entrepreneurs and business owners of the future. I think the real conversation needs to continue, and I don't know how to make an impact. Over the last two years, I've been doing it, you know, meeting with people and meeting with council members and meeting with city staff. And so that's why Sunshine FM exists. It's just my version of, hey, let me see, can I just have conversations here and invite people to this outlet and have a conversation so we can all learn and grow and make the decisions in. In a. In a more collective manner. All right, so that was kind of deep. Thanks for hanging in there. If you did hang in there. If it got kind of a little too in the weeds, I apologize. I think it is. It is a serious conversation to be. Have to be having. I appreciate the fact that Daria Amadei, the CEO of one of the biggest AI companies in the world, world, is basically saying this because then it gives me the lane to also continue talking about some of these, not just the promise of AI, but some of the perils of AI that we all, especially, especially on a local level, need to be mindful of. All right, so Sunshine FM is an experiment in AI. We're building a modern media company for Palm Springs Coachella with just a human, armed with an army of AI agents. Most of the content that you get on here, apart from me speaking into this mic, you know, once a day, maybe twice a day, as we, we get more folks locally involved in conversations, it's AI generated. And while the, let's say the juries out there about AI generated content, I know there's a lot of slop else I know there's a lot of great work being done creatively across various, various sectors of, let's say, inform the information space. And I've always wanted to own a radio station and run a radio station. I am the, the radio station manager of Sunshine fm. And this is not a polished podcast, nor is it a professional radio station. It's me just using AI tools to see what do I need to make workflows more agentic and what do we need to do to actually augment my skill set and my taste and my curation abilities to pass on valid and important vital information to my community at the same time while providing them a backdrop of entertainment that is also AI generated. You heard me say at the top of the hour, Ronnie is one of our first AI artists and she just came out with a new song about the Marilyn Monroe statue in Palm Springs is the forever Marilyn statue. And she just came out with a song called Forever Frozen in the Desert Heat. I've read the lyrics, I have not heard the song in full, but I'm going to close out today's show with Ronnie's new song called Forever Frozen in the Desert Heat.