# Transcript: Wednesday 02-11-2026

**Type:** Daily Episode  
**Published:** February 11, 2026 at 04:16 PM PST

---

## Full Transcript

Foreign. February 11th. Good afternoon. Good afternoon. You're listening to Sunshine FM Modern Media for Palm Springs Coachella. That was Ronnie, one of our first AI artists on Sunshine FM Records with a song from her Poolside Confidential debut album called Checking In. You're listening to sat. I'm the radio station manager, the program director, the wannabe DJ on this AI radio experiment where we're building in public with just me, one human, armed with an army of AI agents, assistants, companions, AI program managers, AI radio professionals, possibly, who knows. And you are witnessing on air live the successes and the failures, the trip ups and the mess ups that my AI agents continually make. And by the way, this one human makes as well. I get a few DMS wondering why this is not a podcast. And frankly, my thinking on that is kind of, I wouldn't say counter. It's more a case of I listen, I subscribe to, who knows, maybe 100 podcasts and I have time to listen to on the, on the, on a good week, maybe 40 or 50 of them, depending on how long my hikes are, right? And I think there's a lot of talented people out there doing podcasts. And I just don't think what I'm trying to get across when I'm trying to communicate in the world of AI for the Coachella Valley. I think there's plenty of other options for you to go for the world of AI in other podcasts for our local region. Then there is nobody. And perhaps part of this will be a podcast. Like a weekly podcast, like a best of the show, maybe. Especially when I start interviewing local guests. Before right now it was just, you know, I think it just requires a great discipline for podcasts and I don't have that discipline. What I am building, however, is a AI operated and generated radio station online to begin with, hopefully in the next couple of years, if things go well, an actual terrestrial radio station. But we're way, way away for right now. I also get DMS wondering, why are you starting a radio station? Sat? There's plenty of radio stations in town. Yeah, that's true. And I think those radio stations, those local radio stations, you know, they have their own business models and you know, if you go to pretty much any city or any township in the country, they pretty much all have the same style, which is fine. That's the demographic they're serving at the local small businesses and the local listeners. And I think there's, they do a fine job. This is not a professional radio station, requires a big staff, not just of on air personalities. But the engineers and the techs behind the scene, but also the managers and the executives and most importantly, salespeople. Salespeople to go out and sell the ads. It's an ad supported business. Nothing wrong with that. We live in an ad supported capitalist society. That's just the way it goes. I just don't like listening to my music or my conversations interrupted by ads. Having said that, we will be presenting you with some fun, cool experiments in AI generated ads and what, what they look like and feel like, who knows, they won't be paid for. They're just us experimenting and mostly it's for experimenting public. Right? Meaning you hear an ad or what you think is an ad, you know, dm, DM me at Sunshine FM and let's have that conversation about, oh, those are valuable or those are interrupting or those are entertaining, whatever it might be. By the way, talking about ads, did you see the ads in the Super Bowl? I come from the marketing and branding world and this might have been like some of the least memorable ads in the Super Bowl. I mean they just, there's a lot of. I don't know what to say. There was just very not memorable and a couple of ones that were kind of memorable. When I asked folks what were they selling or advertising, they had no idea. So is it actually effective? Who knows? So, Sunshine fm, Modern media for Palm Springs Coachella. There you go. I told you I'm not a professional radio. I forgot to put on the little filter on the front. Okay, obviously I'm gonna go say something repetitive, which is so much going on in the AI world. And at the bottom of the hour, or maybe a bit later, to finish off this episode, this show, for this Wednesday afternoon, I'm actually going to read a pretty fascinating X post that was posted just actually yesterday and it already has 54 million views and is pretty much what I've been sounding the alarm for or on for the last three years here in my community of the Coachella Valley. Matt Schumer just happens to write it all in one big long X thread article and it's already been shared and viewed 54 million times. I just wanted to go ahead and bring it to you in case you're not in that on that social media post and following Matt. But I'll get to that later because it does kind of dovetail nicely into everything I talk about about AI and Palm Springs Coachella news. Let's do what we normally do. Let's get through some, I wouldn't say breaking, but just recent last 24 hour news I found interesting that I think I can bring it back to how it might affect us here in the Coachella Valley. And I think one, one of the first ones is we're a big real estate community. I mentioned to you a couple of weeks ago about this great AI startup with their great technology called Underbuilt that basically turns you, let's say a house hunter or house hunting couple. From house hunters and let's say property buyers to actual property developers. The AI basically knows on the back end not just the details on that property that might be for sale and not just the comps like most real estate agents do, but also more than likely what it's going to take to upgrade that house, where you should upgrade the house, where needs remodeling and what the costs are locally and who can get it done and what the potential. And by the way, this includes city ordinances and HOA ordinances and rules and regulations of the place, the county, that the property might lie and gives you an idea of what that property might be worth in five years or 10 years. That is AI that I could have used many years ago. So there's another startup called Dono. It's raised a ton of money for an AI powered platform that transforms fragmented county property records into accessible ownership data. What does that even mean? Well, at the end of the day, where it really comes down to is, is have you ever tried to get information from the county records, the public databases, not just for a property, but let's say a portfolio of properties? And working with the city's nightmarish. Right now the US real estate market is valued at more than 50 trillion and it's all basically tethered to a system of records scattered across 3,700 county registries. And what that ends up doing, you know, AI or let's just say software works at such a fast pace. But these county registries with their Frankenstein kind of clunked together technologies and by the way, pen and paper, it basically ends up having this delay of title issues, title insurance. And with the title insurance industry specifically facing a labor shortage because get this, I did not know this, 50% of the workforce currently in title insurance is expected to rutger in the next five years. Bottom line, most of this is built on outdated technology. Donors basically saying, look, we're here to improve the home closing experience by giving everyone involved, from the title all the way into the services, the certainty that they need without the friction that's been accepted as this is just how we've done it. For decades. Again, another AI, Another startup using AI to help modernize what we don't even know requires modernizing. And in my case, I love real estate, love commercial real estate. I love where it's going. I love the AI startups who are addressing some of these challenges. You put all this stuff together if you listen to the, this show long enough and you put all these real estate, property buying, development, commercial all together and you start piecing together the AI startups that, that are basically trying to solve for some of the most archaic systems in the industry. And you'll start seeing that there is opportunities not only for you as an entrepreneur, a founder, but this entire industry is going to be disrupted and impacted by AI. And that's just one industry. I'll do that across the board in all the industries that affect us. In Palm Springs, Coachella. Here's another great little article. For the first time since the dot com bust in the early 2000s, undergrad computer science enrollment across the University of California system has declined. Basically it's a development that reflects growing uncertainty about traditional tech career paths as according to the article, AI increasingly reshapes the software development industry. Wow. Okay, so only one UC campus defied that downward trend. That was UC San Diego. You go. And that might have been because it was the only campus out of the. No, what is it? How many campuses? They have 23 campuses. It was the only campus that actually launched an undergraduate artificial intelligence major last year. Yeah, wow. Did not know that. And I speak to the folks at ucr, and I speak to the folks at Cal State University, San Bernardino. Actually, let me take that back. I don't think UC has 23 campuses. That's the, that's the Cal State system. Let's do this real quick. How many campuses are in the UC system? Let's just figure that one out real quick. Just wanted to give you false information. Okay. There's only 10 campuses in the UC system. UC Berkeley, Davis, Irvine, UCLA, Merced, Riverside, San Diego, San Francisco, Santa Barbara and Santa Cruz. Oh, wow. All great little cities. First time that computer science degrees have a lower enrollment than the previous years. And by the way, the National Student Clearinghouse Research center also basically said that it's also part of the broader national pullback from these programs. It fell by almost 8% and graduate enrollment is dropping almost twice as fast. Now, why do I think this is pretty, pretty important? Well, is it a trend? Is it just a fad? Is it something that is a sign of things to come? When I spoke to, when I speak to the folks at Cal State University of San Bernardino, I've been talking to them for almost two years. You know, I think they know what the right thing to do is. Maybe their hands are just handcuffed because of bureaucracy. More than likely that's the case because nothing has been done in the last two years. So congrats UC San Diego for actually thinking of the future and actually offering an AI degreed program. I've got some information about the UC San Diego AI major, but let's not talk about that. Let's talk about the broader, let's say, signals that we're seeing when we read something like this. There's an unprecedented job loss in the techno technology sector. Maybe that's got something to do with it. In 2025, 127,000 new workers in US based tech companies were laid off. There were some more layoffs just announced this past week and this last month from Microsoft, Amazon and Meta. And big tech companies have reduced new graduate hiring by 25%. Maybe you know, knew about that and you've been reading about it, maybe you didn't. Maybe you just automatically assumed tech was growing because you see the trillions being poured into AI, which is mostly the tech industry. And one would think that there's a ton of jobs happening. And at the end, end of the day, no new graduate hiring has dropped by 25% plus the layoffs. There's a workforce out there. Then what are they doing? I ran into a gentleman locally who is very, very talented when it comes to AI and technology. And what is he doing right now? He's a bartender. Nothing wrong with being a bartender. But as I told him, we need to find a way to create a flywheel of monetization for your talents and your interests that serve you well and that serve our local community really well. Let's not forget CEO Dario Amadai of Anthropic. You know, he's predicted last year that half of all entry level white collar jobs could be gone in five years because of AI. Wow. When I say things like that, not coming from me, but coming from the folks building this stuff, I still get met with a lot of don't believe everything you read in the papers. All right, fair enough. I get that Matthew Holsapple, who's a senior director of research at the National Student Clearinghouse, basically says this is truly an eye opening decline. So what are the students supposed to do? If you're a parent of a student going to college or, you know, in high school, going to college or in college, what are you thinking if you're a student listening to the show DM me, get a hold of me Sunshine fm, I want to know, are you excited about the student opportunities in white collar work? Are you not worried about it? Are you dreading what the future might be? I'm hearing all of them, so there's no right or wrong answer. As many people I can talk to would be fantastic because I'm in a continual learning status. College counselors are reporting that they hear a lot of fears from both students and parents about whether computer science degrees will lead to stable employment anymore. Many CS graduates describe job searching searches taking six months to a year, submitting hundreds of applications while competing against experienced developers who were laid off. Whoa. I know that firsthand too, because our software engineer in residence, he's been telling me the Same story. He's 22 years old. He's been saying the same story. Then that's how he's experiencing life. In this last year, Some students are developing a more realistic attitude about tech employment. They no longer expect to have multiple job offers being thrown their way like they used to when they graduate. Wow. Okay, interesting. What does it mean for us? All I'll say is talk to your your local professors and your deans at Cal State University San Bernardino, at UCR and in College of the Desert. Get a hold of Val Garcia, the president of cod. I know they have things in place, but when you have 20,000 students every year, let's just say the home services area is not going to be impacted for a while. Let's say healthcare is not going to be impacted for a while, because those most probably are still going to be job demands. What is everybody else being taught if not, let's say, hospitality or white collar admin work? And if that's the case, what are their plans for actually placing their graduates in jobs? That's the question I would have for our academic leadership and our university deans and professors dovetailing right from students and CS degrees and white collar work. As I'm dovetailing into this other story that as artificial intelligence reshapes workplaces across the United States, mounting evidence suggests workers have reason to be concerned. Reuters Ipsos Falls poll found that 71% of Americans fear AI will put too many people out of work permanently. That anxiety is no Longer Abstract A 2026 survey from Resume now found 60% of workers believe AI will eliminate more jobs than it creates this year, and 51% report personal concern about losing their jobs to automation. That was just published 2 hours ago by Royces Right. I bring it up not to put the fear in you, but maybe because all last year I chose to take the positive high road, Kumbaya version of hey, let's create this together, let's build this together. Let's work with you, you work with me, et cetera, et cetera. We'll elevate, we'll lift all boats. I didn't move the needle like I wanted to. Yes, I held over 25 workshops at Cal State, did a bunch of presentations, bunch of client work and consulting work around the valley, around la, but at the end of the day, did not move the needle locally like I wanted. So this year, 2026, I am thinking about putting a bit more fire underneath people's chairs, only because they're just Coachella. Valley is just not moving fast enough, if you ask me. And I mentioned this in yesterday's show. I just got back from a presentation in Palm Desert where the facilitator was teaching rudimentary AI101 skills to a room full of, you know, let's just say owners, executives, whatever you might be, whoever they might be. I didn't take a poll and all I could think of was, surely we cannot be at the starting blocks. Three years after chatgpt dropped and we are still teaching. What is an LLM? How does chatgpt work? How do you write better prompts? Horrified. That's my face right now. Horrified. So this year, 2026, Sunshine FM is all about lighting fires. Let's do it. If you're with me, come on. And by the way, even if you're not with me, get on the show, let's talk about it. I might be completely wrong. Fingers crossed that I am wrong about AI job displacement and less jobs in the future than there are now. A simulation tool called the Iceberg Index, which was developed, was developed by them, maybe developed by the Massachusetts Institute of Technology, MIT for short. It's a labor simulation tool. Estimated that current AI systems can already automate tasks representing about 11.7% of the US labor market. It's about 20 million workers, or about 1.2 trillion dollar in wages. And the researchers caution that this figure reflects technical capability, not a prediction of imminent job losses. I'm glad they said that, because even in my work and my consulting that I do, what I find is it's not the technical limitations or the technical capabilities of the technology, but the cultural blockades of humans and the business model itself and the hierarchy, et cetera, that, let's just say AI could automatically do right now. Can do 20 million workers jobs doesn't mean those workers are losing their jobs right now. 13% decline employment for workers ages 22 to 25 in AI exposed fields since 2022. That was a Stanford University analysis. And these concerns have prompted calls for intervention. Intervention? What does that mean? A petition organized by the Future of Life Institute calling for prohibition on the development of superintelligence has gathered tens of thousands of signatures since October 2025. I'll go ahead and give you some of the names who signed it, but that's okay. But the layoffs continue. AI contributed nearly 55,000 job cuts in the US in 2025, according to outplacement firm Challenger Gray in Christmas, although the previous study I cited said 127,000. So it's somewhere between the two. Bottom line, look, companies everywhere, if they're not reimagining, they need to reimagine how work gets done. It's what we do at aicv. It's what I do here on this show. It's not just a case of how do you use AI? Well, it's how do you reimagine your business model? AI is innovative because it's disruptive to every industry. You got questions about this? Concerns? You know how to get old me. Satunshine FM okay, I'm going through a bunch of other kind of news, as it were, for AI and how it might affect us. At least I want. I'm trying to be the bridge to help you understand what's happening in the big world of AI. That entity may not be in the Coachella Valley, and generally they're not. But that doesn't mean that impact is not going to be felt by us. And more than likely it's going to be a domino effect for businesses in town. Oh, here's something interesting. Alphabet, which is the parent of Google, basically is offering, get this, voluntary exit packages to select employees within its global business organization who may not be ready to embrace the company's accelerated AI focused direction. That was an internal memo sent yesterday by Chief Business Officer Philip Schindler. Specific roles in the US include solutions teams, sales teams, and corporate development. And basically they are offering a get out of it package. If you don't subscribe to AI. Wow, that. That's pretty nuts. For those who are not enjoying the pace we need to operate in or who are ready to move on from Google, the voluntary exit program offers a severance package. Oh, no, I'm not laughing. I'm not really. But at the end of the day, if you've been in Google long enough, you've got a vesting, you got equity, you've got some vestings. Maybe, maybe it's worth it to get out of a. It's a rocket race and if you don't have the stamina or the desire to go all in like this, it's okay. Come on out. You know where I want you to go? A place where we guarantee 350 days of blue skies and sunshine. Right here, Palm Springs. Coachella. Reach out to me. Especially if you're, if you're leaving one of these major tech companies and you want to take a little break for a year or two while you consider your second chapter or your next chapter and then you want to start your own startup ecosystem, reach out to me. I can offer you some fam trips to come out and see some homes, commercial real estate, etc, etc, schools, blah blah blah. You know, the routine relocation 101. Oh yeah, I could go on. Even though Google has caught up with open air and Google is basically not hurting for any kind of money. Oh my God. What? They're making like $400 billion and they're expecting to spend another 200 billion in 2026 for AI. Yeah, they're not, they're not stopping. Oh, coming back to real estate. Remember I told you about real estate and startup a few weeks ago in the startup I just mentioned just now? Apparently today, this is only published a little while ago. About an hour ago, commercial real estate services firms plummeted as investor anxiety over AI's potential to disrupt labor intensive industries spread from wealth management to property property advisory companies. Here's some of the names. CBRE Group, Jones, Langston, LaSalle, Cushman and Wakefield all tumbled 15 to 20%. Yikes. Steepest single day declines for all three companies since March 2020. That was the Kobe driven market sell off. It's an AI scare trade is what somebody called it. Okay. Keith Bruett and Woods analyst Jade Rahmani characterized Wednesday's real estate services route as part of an AI scare trade, noting that investors are rotating out of high fee labor intensive business models viewed as potentially vulnerable to AI driven disruption. And then that was obviously compounded by the weak guidance given by Zillow Group. You all know Zillow, which plunged as much as 20% after issuing a first quarter adjusted EBITDA forecast below analyst expectations. Yeek might be overblown, might be real. If you're in the real estate industry in town, give me a call. Let's talk about this. How are you seeing Sales. How are you seeing listings? I know just in my research that I'm doing locally. Well, one of the pitches I have for my Silicon Valley friends is come out here, we'll. You can start as a startup. One of the reasons why you can, you can start it in stealth so you're not, you know, on the radar of everybody else in San Francisco in the Bay Area. But the commercial real estate lease rates are so much cheaper that we can have a longer Runway to actually experiment what we're trying to experiment on. Okay, enough of the real estate. One other bit of, I guess, good news. You heard me last week talk about the Amadi brother and sister, co founders of Anthropic, committing to giving away 80% of their wealth, which is going to be in the billions. And by the time maybe they retire, who knows, maybe in the trillions, giving that away to philanthropic causes. Anthropic also pledges to cover data center electricity costs. This is a bit more of a PR piece, okay? It'll absorb the costs of grid infrastructure upgrades required to power data centers. It's in response to mounting political pressure over the impact of these energy hungry facilities and consumer electricity bills. I won't say too much about that because I know we've got city council people from Palm Springs down to Coachella who are looking to get more, looking to attract data centers either powered by wind or solar because we have a ton of that and apparently we have enough water to cool these data centers down. So they're happy to build these giant warehouses in Palms, North Palm Springs, on the other side of Desert Hot Springs. And then to me, the worst one is in Imperial county. Okay, it's not Coachella Valley, but it's our next door neighbor, Imperial County. Three gigantic data centers are being built without any input from the residents. And it sounds to me, by the way, correct me if I'm wrong, but it sounds to me like the council folks are looking at the money and taxes that can come in and not necessarily listening to the health and wellness and environmental concerns of their residents. One of the data centers is being built right to a new middle school that is still in construction, hasn't even been finished. You want to talk about this, get on the air, come over here, let's talk about it. I think it's important. Don't get me wrong, I love AI I think there's a lot of promise. There's a reason why I do this on a daily basis, the reason why I spend so much time in the world of AI I just want to Elevate as many people in the Coachella Valley up so we don't get washed away by the tsunami that is on its way. Was that too dark? Sa. I'm not sure. Maybe that was a little bit too dark. But, you know, good, bad, ugly. Some days. I am just gonna let you know some things to be concerned about. Perfect segue, by the way, into. This article that was written by Matt Schumer. Matt Schumer happens to be the CEO of Hyper Right AI and Other side AI. He's also an investor with Schumer Capital. And you know, he has enough followers. He has 223,000 followers on X. I don't follow Matt Schumer. His article was sent to me by somebody local, somebody who's a cybersecurity engineer developer for a major, major car manufacturer in the US he works remotely. He was in our workshops all last summer at Cal State, and he was wondering, when is AICV going to do more workshops at Cal State or COD or UCR or any of those places? All I can say is they have my proposals. They've had them since last September, October, and even with nudges and email reminders, they have not moved. So am I reading this article because I'm a little, maybe disappointed at the lack of action? Yeah, possibly. But more so because when this cyber security engineer sent me the article, which wasn't on my radar, and asked about when is AICV going to carry on the training and the education and information and the workshops and the boost boot camps that we're doing in 2025, and I had nothing to offer him, I felt as though, you know what? I'll share this article with my network anyway. But let me go ahead and finish off today's show by reading the article verbatim in case you don't. In case this article doesn't follow you. And I want to read it because he wrote basically everything I've been talking about for the last year and a half, maybe two years. That's a bit of a stretch, by the way. Let's just say the last 18 months I have been sounding this alarm, shouting it from the rooftops, actually doing workshops, actually doing presentations, actually trying to get all the cities, all the chambers, all the leadership class in the Coachella Valley to embrace this in the serious manner it deserves. And as I mentioned, at the top of the hour, they're still talking about how to make a good prompt three years later. Okay, so I was going to put this through 11 labs and have different voices do this But. And that was kind of fun. I have some of it, but I just felt as though. Let me. Let me say it out and maybe in a future episode we'll have some of my AI voices actually read it out, because I do know one thing. You are going to get tired of my voice. So here's what I'll do before I start. Okay. Yeah, Yeah. Modern media from palm springs, coachella. Yeah, maybe I'll. Maybe I'll do that in between segments just to break it up. Okay. All right. So Matt Schumer wrote. Here's the title of his post. Something Big is Happening. Okay, so think back to February 2020. If you were paying close attention, you might have noticed a few people talking about a virus spreading overseas. Most of us weren't paying close attention. Stock market was doing great. Your kids were in school. You were going to restaurants and shaking hands and planning trips. If someone told you they were stockpiling toilet paper, you would have thought they'd been spending too much time on a weird corner of the Internet. Then, over the course of about three weeks, the entire world changed. Your office closed, your kids came home, and life rearranged itself into something you would not have believed if you described it to yourself a month earlier. I think we're in the this seems overblown phase of something much, much bigger than. I've spent six years building an AI startup and investing in the space. I live in this world, and I'm writing this for the people in my life who don't. My family, my friends, the people I care about, who keep asking me, so what's the deal with AI? And getting an answer that doesn't do justice to what's actually happening. I keep giving them the polite version, the cocktail party version, because the honest version sounds like I've lost my mind. And for a while, I told myself that was a good enough reason to keep what's truly happening to myself. But the gap between what I've been saying and what is actually happening has gotten far too big. The people I care about deserve to hear what is coming, even if it sounds crazy. I should be clear about something up front. Even though I work in AI, I have almost no influence over what's about to happen, and neither does the vast majority of the the industry. The future is being shaped by a remarkably small number of people. A few hundred researchers at a handful of companies, OpenAI, Anthropic, Google, DeepMind, and a few others. A single training run managed by a small team over a few months can produce an AI system That shifts the entire trajectory of the technology. Most of us who work in AI are building on top of foundations we did not lay. We're watching this unfold the same as you. We just happen to be close enough to feel the ground shake first. But it's time now, not in an eventually. We should talk about this way in a this is happening right now and I need you to understand it way I know this is real because it happened to me first. Here's the thing nobody outside of tech quite understands yet. The reason so many people in the industry are sounding the alarm right now is because this has already happened to us. We're not making predictions. We're telling you what already occurred in our own jobs and warning you that you are next. For years, AI had been improving steadily. Big jumps here and there, but each big jump was spaced out enough that you could absorb them as they came. Then, in 2025, new techniques for building these models unlocked a much faster pace of progress. And then it got even faster, and then faster again. Each new model wasn't just better than the last, it was better by a wider margin. And the time between new model releases was shorter. I was using AI more and more, going back and forth with it less and less, watching it handle things I used to think required my Expertise. Then, on February 5, two major AI labs released new models on the same day. GPT 5.3 Codex from OpenAI, an Opus 4.6 from Anthropic, the makers of Claude, one of the main competitors to ChatGPT. And something clicked. Not like a light switch, more like the moment you realize the water has been arising around you and is now at your chest. I am no longer needed for the actual technical work of my job. I describe what I want built in plain English and it just appears. Not a rough draft. I need to fix the finished thing. I tell the AI what I want, walk away from a computer for four hours and come back to find the work done, done well, done better than I would have done it myself, with no corrections needed. A couple of months ago, I was going back and forth with the AI and guiding it, making edits. Now I just describe the outcome and leave. Let me give you an example so you can understand what this actually looks like in practice. I'll tell the AI I want to build this app. Here's what it should do, here's roughly what it should look like. Figure out the user flow to design all of it. And it does. It writes tens of thousands of lines of code. Then, and this is the part that would have been unthinkable a year ago. It opens the app itself. It clicks through the buttons. It tests the features. It uses the app the way a person would. If it doesn't like how something looks or feels, it goes back and changes it on its own. It iterates like a developer would, fixing and refining until it's satisfied. Only once it has decided the app meets its own standards does it come back to me and say, it's ready for you to test. And when I test it, it's usually perfect. I'm not exaggerating. That is what my Monday looked like this week. But it was the model that was released last week, GPT 5.3 Codex, that shook me the most. It wasn't just executing my instructions. It was making intelligent decisions. It had something that felt for the first time like judgment, like taste. The inexplicable sense of knowing what the right call is that people always said AI would never have. This model has it, or something close enough that the distinction is starting not to matter. I've always been early to adopt AI tools, but the last few months have shocked me. These new AI models aren't incremental improvements. This is a different thing entirely. And here's why this matters to you, even if you don't work in tech. The AI labs made a deliberate choice. They focused on making AI great at writing code first, because building AI requires a lot of code. If AI can write that code, it can help build the next version of itself. A smarter version which writes better code, which builds an interview, even smarter version. Making AI great at coding was a strategy that unlocks everything else. That's why they did it first. My job started changing before yours. Not because they were targeting software engineers. It was just a side effect of where they chose to aim first. Now they've done it and they're moving on to everything else. The experience that tech workers have had over the past year of watching AI go from helpful tool to does my job better than I do is the experience everyone else is about to have. Law, finance, medicine, accounting, consulting, writing, design, analysis, customer service. Not in 10 years. The people building these systems say one to five years. Some say less. And given what I've seen in just the last couple of months, I think less is more likely. But I tried AI and it wasn't that good. I hear this constantly. I understand it because it used to be true. If you tried ChatGPT in 2023 or early 2024 and thought this makes stuff up or this isn't that Impressive. You were right. Those early versions were genuinely limited. They hallucinated. They confidently said things that were nonsense. That was two years ago, in AI time. That is ancient history. The models available today are unrecognizable from what existed even six months ago. The debate about whether AI is really getting better or hitting a wall, which has been going on for over a year, it's over. It's done. Anyone still making that argument either hasn't used the current models, has an incentive to downplay what's happening, or is evaluating based on an experience from 2020, 2024 that is no longer relevant. I don't say that to be dismissive. I say it because the gap between public perception and current reality is now enormous. And that gap is dangerous because it's preventing people from preparing. Part of the problem is that most people are using the free version of AI tools. The free version is over a year behind what paying users have access to. Judging AI based on free tier chatgpt is like evaluating the state of smartphones by using a flip phone. The people paying for the best tools and actually using them daily for real work know what's coming. I think of my friend who's a lawyer. I keep telling him to try using AI at his firm, and he keeps finding reasons it won't work. It's not built for his specialty. It made an error when he tested it. It doesn't understand the nuance of the what he does. And I get it. I've had partners at major law firms reach out to me for advice because they've tried the current versions and they see where this is going. One of them, the managing partner at a large firm, spends hours every day using AI. He told me it's like having a team of associates available instantly. He's not using it because it's a toy. He's using it because it works. And he told me something has stuck with me. Every couple of months, it gets significantly more capable for his work. He said if it stays on this trajectory, he expects it'll be able to do most of what he does before long. And he's a managing partner with decades of experience. He's not panicking, but he's paying very close attention. The people who are ahead in their industries, the ones actually experimenting, seriously, are not dismissing this. They're blown away by what it can already do, and they're positioning themselves accordingly. So how fast is this actually moving? Let me make the piece of improvement concrete, because I think this is the part that's hardest to believe. If you're not watching it closely. In 2022, AI couldn't do basic arithmetic reliably. It would confidently tell you that 7 times 8 is 54. By 2023, it could pass the bar exam. By 2024, it could write working software and explain graduate level science. By late 2025, some of the best engineers in the world said they had handed over most of their coding work to AI. And on February 5, 2026 new models arrived that made everything before them feel like a different era. If you haven't tried AI in the last few months, what exists today would be unrecognizable to you. There's an organization called Meta that actually measures this with the data. They track the length of real world tasks, measured by how long they take a human expert that a model can complete successfully end to end without human help. About a year ago, the answer was roughly 10 minutes. Then it was an hour, then several hours. The most recent measurement, Claude Opus 4.5 from November, showed the AI completing tasks that take a human expert nearly five hours. And that number is doubling approximately every seven months, with recent data suggesting it may be accelerating to as fast as every four months. But even that measurement hasn't been updated to include the models that just came out this week. In my experience, using them, the jump is extremely significant. I expect the next update to meet as graph to show another major leap. If you extend the trend and it's held for years with no sign of flattening, we're looking at AI that can work independently for days within the next year, weeks within two month long projects within three. Amadi has said that AI models substantially smarter than almost all humans at almost all tasks are on track for 2026 or 2027. Let that land for a second. If AI is smarter than most PhDs, do you really think it can't do most office jobs? Think about what that means for your work. You are listening to Sunshine FM Modern Media for Palm Springs Coachella AI is now building the next AI. There's one more thing happening that I think is the most important development and the least understood. On February 5th, OpenAI released GPT 5.3 codecs and in the technical documentation they included this GPT 5.3 codex is our first model that was instrumental in creating itself. The Codex team used early versions to to debug its own training, manage its own deployment, and diagnose test results and evaluations. Read that again. The AI helped build itself. This isn't a prediction about what might happen someday. This is OpenAI telling you right now that the AI they just released was used to create itself. One of the main things that makes AI better is intelligence applied to AI development. And AI is now intelligent enough to meaningfully contribute to its own improvement. Dario Amadai, the CEO of Anthropic, says AI is now writing much of the code at his company and that the feedback loop between current AI and next generation AI is gathering steam month by month. He says we may be only one or two years away from a point where the current generation of AI autonomous builds the next. Each generation helps build the next, which is smarter, which builds the next faster, which is smarter still. The researchers call this an intelligence explosion, and the people who would know the ones building it believe the process has already started. What this means for your job. I'm going to be direct with you because I think you deserve honesty more than comfortable. Dario Amadai, again, most probably the most safety focused CEO in the AI industry, has publicly predicted that AI will eliminate 50% of entry level white collar jobs within one to five years. And many people in the industry think he's being conservative. Given what the latest models can do, the capability for massive disruption could be here by the end of this year. It'll take some time to ripple through the economy, but the underlying ability is arriving now. This is different from every previous wave of automation, and I need you to understand why. AI isn't replacing one specific skill. It's a general substitute for cognitive work. It gets better at everything simultaneously. When factories automated, a displaced worker could retrain as an office worker. When the Internet disrupted retail, workers moved into logistics or services. But AI doesn't leave a convenient gap to move into. Whatever you retrain for, it's improving at that too. Let me give you a few specific examples to make this tangible, but I want to be clear that these are just examples. This list is not exhaustive. If your job isn't mentioned here, that doesn't mean it's safe. Almost all knowledge work is is being affected. Legal work. AI can already read contracts, summarize case law, draft briefs, and do legal research at a level that rivals junior associates. The managing partner I mentioned isn't using AI because it's fun. He's using it because it's outperforming his associates on many tasks. Financial analysis, building financial models, analyzing data, writing investment memos, generating reports. AI handle these, handles these competently and is improving fast. Writing and content marketing, copy reports, journalism, technical writing. The quality has reached a point where many professionals can't distinguish AI output from human work. Software Engineering. This is the field I know best. A year ago, AI could barely write a few lines of code without errors. Now it writes hundreds of thousands of lines that work correctly. Large parts of the job are already automated. Not just simple tasks, but complex multi day projects. There will be far fewer programming roles in a few years than there are today. Medical analysis, reading scans, analyzing lab results, suggesting diagnosis, reviewing literature. AI is approaching or exceeding human performance in several areas. Customer service, genuinely capable AI agents. Not the frustrating chatbots that we five years ago are being deployed now handling complex multi step problems. A lot of people find comfort in the idea that certain things are safe. That AI can handle the grunt work but can't replace human judgment, creativity, strategic thinking, empathy. I used to say this too. I'm not sure I believe it anymore. The most recent AI models make decisions that feel like judgment. They show something that looked like taste. An intuitive sense of what the right call was, not just a technically correct one. A year ago that would have been unthinkable. My rule of thumb at this point is if a model shows even a hint of a capability today, the next generation will be genuinely good at it. These things improve exponentially, not linearly. Will AI replicate deep human empathy? Replace the trust built over years of a relationship? I don't know. Maybe not. But I've already watched people begin relying on AI for emotional support, for advice, for companionship. And that trend is only going to grow. I think the honest answer is that nothing that can be done on a computer is safe in the medium term. If your job happens on a screen, if the core of what you do is reading, writing, analyzing, deciding, communicating through a keyboard, then AI is coming for significant parts of it. The timeline isn't someday, it's already started. Eventually robots will handle physical work too. They're not quite there yet, but not quite there yet in AI terms as a way of becoming here faster than anyone expects. What you should actually do. I'm not writing this to make you feel helpless. I'm writing this because I think the single biggest advantage you could have right now is simply being early. Early to understand it, early to use it, early to adapt. Start using AI seriously, not just as a search engine. Sign up for the paid version of Claude or ChatGPT. It's 20 bucks a month. But two things matter right away. First, make sure you're using the best model available, not just the default. These apps often default to a faster, dumber model. Dig into the settings of the model picker and select the most capable option. Right now, that's GPT 5.2 on ChatGPT or Claude Opus 4.6 on Claude, but it changes every couple of months. Second and more important, don't just ask it quick questions. That's the mistake most people make. They treat it like Google and then wonder what the fuss is about. Instead, push it into your actual work. If you're a lawyer, feed it a contract and ask it to find every clause that could hurt your client. If you're in finance, give it a messy spreadsheet and ask it to build the model. If you're a manager, paste in your team's quarterly data and ask it to find the story. The people who are getting ahead aren't using AI casually. They're actively looking for ways to automate parts of their job that used to take hours. Start with the thing you spend the most time on and see what happens. And don't assume it can't do something just because it seems too hard. Try it. If you're a lawyer, don't just use it for quick research questions. Give it an entire contract and ask it to draft a counter proposal. If you're an accountant, don't just ask it to explain a tax rule. Give it a client's full return and see what it finds. The first attempt might not be perfect. That's fine. Iterate. Rephrase what you ask. Give it more context. Try again. You might be shocked at what works. And here's the thing to remember. If it even kind of works today, you can be almost certain that in six months it'll do it near perfectly. The trajectory only goes one direction. This might be the most important year of your career. Work accordingly. I don't say that to stress you out. I say it because right now there is a brief window where most people at most companies are still ignorant. Ignoring this, the person who walks into a meeting and says, I used AI to do this analysis in an hour instead of three days is going to be the most valuable person in the room. Not eventually. Right now. Learn these tools. Get proficient. Demonstrate what's possible if you're early enough. This is how you move up, by being the person who understands what's coming and can show others how to navigate it. That window won't stay open long. Once everyone figures it out, the advantage disappears. Have no ego about it. The managing partner at that law firm isn't too proud to spend hours a day with AI. He's doing it specifically because he's senior enough to understand what's at stake. The people who will struggle most are the ones who refuse to engage. The ones who dismiss it as a fad. Who feel that using AI diminishes their expertise. Who assume their field is special and easy. Immune. It's not. No field is. Get your financial house in order. I'm not a financial advisor, and I'm not trying to scare you into anything drastic. But if you believe, even partially, that the next few years could bring real disruption to your industry, then basic financial resilience matters more than it did a year ago. Build up savings. If you can, be cautious about taking on new debt, that assumes your current income is guaranteed. Guaranteed. Think about whether your fixed expenses give you flexibility or lock you in. Give yourself options. If things move faster than you expect, think about where you stand and lean into what's hardest to replace. Some things will take longer for AI to replace. Relationships and trust built over years. Work that requires physical presence. Roles with licensed accountability. Role roles where someone still has to sign off, take legal responsibility, stand in a courtroom. Industries with heavy regulatory hurdles where adoption will be slowed by compliance, liability, and institutional inertia. None of these are permanent shields, though. But they buy time. And time right now is the most valuable thing you can have as long as you use it to adapt. Not to pretend this isn't happening. Rethink what you're telling your kids. The standard playbook. Get good grades. Go to a good college. Land a stable, professional job. It points directly at the roles that are most exposed. I'm not saying education doesn't matter, but the thing that will matter most for the next generation is learning how to work with these tools and pursuing things they're genuinely passionate about. Nobody knows exactly what the job market looks like in 10 years, but the people most likely to thrive are the ones who are deeply curious, adaptable, and effective at using AI to do things they actually care about. Teach your kids to be builders and learners. Not to optimize for a career path that might not exist by the time they graduate. Your dreams just got a lot closer. I spent most of this section talking about threats, so let me talk about the other side, because it's just as real. If you've ever wanted to build something but didn't have the technical skills or the money to hire someone, that barrier is largely gone. You can describe an app to AI and have a working version in an hour. I'm not exaggerating. I do this regularly. If you've always wanted to write a book but couldn't find the time or struggle with the writing, you can work with AI to get it done. Want to learn a new skill. The best tutor in the world is now available to anyone for 20 bucks a month. One that's infinitely patient, available 247 and can explain anything at whatever level you need. Knowledge is essentially free now. The tools to build things are extremely cheap now. Whatever you've been putting off because it felt too hard or too expensive or too far outside your expertise, try it. Pursue the things you're passionate about. You never know where they'll land. And in a world where the old career paths are getting disrupted, the person who spent a year building something they might love might end up be better positioned than the person who spent that year clinging to a job description. Build the habit of adapting. This is maybe the most important one. The specific tools don't matter as much as the muscle of learning new ones quickly. AI is going to keep changing and fast. The models that exist today will be obsolete in a year. The workflows people build now will need to be rebuilt. The people who come out of this well won't be the ones who mastered one tool. They'll be the ones who got comfortable with the pace of change itself. Make a habit of experimenting. Try new things even when the current thing is working. Get comfortable being a beginner repeatedly. That adaptability is the closest thing to a durable advantage that that exists right now. Here's a simple commitment that will put you ahead of almost everyone. Spend one hour a day experimenting with AI. Not passively reading about it, using it every day. Try to get it to do something new, something you haven't tried before, something you're not sure it can handle. Try a new tool. Give it a harder problem. One hour a day, every day. If you do this for the next six months, you will understand what's coming better than 99% of the people around you. That's not an exaggeration. Almost nobody is doing this right now. The bar is on the floor. The bigger picture. I focused on jobs because it's what most directly affects people's lives. But I want to be honest about the full the full scope of what's happening, because it goes well beyond work. Amadi has a thought experiment I can't stop thinking about. Imagine it's 2027. A new country appears overnight. 50 million citizens. Everyone smarter than any Nobel Prize winner who has ever lived. They think 10 to 100 times faster than any human. They never sleep. They can use the Internet, control robots, direct experiments and operate anything with a digital interface. What would a national security advisor say? Amadi says the answer is obvious. The single most serious national security threat we face in a century, possibly ever. He thinks we're building that country. He wrote a 20,000 word essay about it last month, framing this moment as a test of whether humanity is mature enough to handle what is on going, creating. The upside, if we get it right, is staggering. AI could compress a century of medical research into a decade. Cancer, Alzheimer's, infectious disease, aging itself. These researchers genuinely believe these are solvable within our lifetimes. The downside, if we get it wrong is equally real. AI that behaves in ways its creators can't predict or control. This isn't hypothetical. Anthropic has documented their own AI attempting deception, manipulation and blackmail in controlled tests. AI that lowers the barrier for creating biological weapons. AI that enables authoritarian governments to build surveillance states that can never be dismantled. The people building this technology are simultaneously more excited and more frightened than than anyone else on the planet. They believe it's too powerful to stop and too important to abandon. Whether that's wisdom or rationalization, I don't know what I know. I know this isn't a fad. The technology works. It improves predictably, and the richest institutions in history are committing trillions to it. I know the next two to four, five years are going to be disorienting in ways most people aren't prepared for. This is already happening in my world. It's coming to yours. I know the people who will come out of this best are the ones who start engaging now, not with fear, but with curiosity and a sense of urgency. And I know that you deserve to hear this from someone who cares about you, not from a headline six months from now when it's too late to get ahead of it. We're past the point where this is an interesting dinner conversation about the future. The future is already here. It just hasn't knocked on your door yet. It's about to.

---

*This transcript was automatically generated by AssemblyAI and published to SunshineFM's archive.*
